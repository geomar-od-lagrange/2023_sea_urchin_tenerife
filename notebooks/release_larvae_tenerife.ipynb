{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d268d4-d726-42d2-8fbb-cc0f4c848942",
   "metadata": {},
   "source": [
    "# Parcels run Tenerife\n",
    "- weekly release; 1 day in start_week of start_year\n",
    "- location: around tenerife in cells <500m depth\n",
    "- release in layer 1-5 \n",
    "- no mortality in parcels run, done in analysis part\n",
    "- output dt: 24h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f775f7-bb0a-4e00-aee0-cd4dcc9dfb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "nesh-fe1\n"
     ]
    }
   ],
   "source": [
    "from parcels import (\n",
    "    AdvectionRK4_3D,\n",
    "    ErrorCode,\n",
    "    FieldSet,\n",
    "    JITParticle,\n",
    "    ParticleSet,\n",
    "    Variable,\n",
    "                    )\n",
    "import os\n",
    "from operator import attrgetter\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import parcels\n",
    "from shapely.geometry import Polygon, Point\n",
    "import cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.release_zones import (\n",
    "    csv_to_polygons_lon_lat,\n",
    "    get_uniform_random_latlon_in,\n",
    "    get_uniform_random_latlon_close_to_polygon,\n",
    "    get_uniform_random_latlon_within_polygon,\n",
    ")\n",
    "print(parcels.version)\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a16ff-4407-4526-87e2-2628033af531",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099b4111-b794-4a89-8147-3a22d96471eb",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "RNG_seed = 123\n",
    "number_particles=10000#new\n",
    "\n",
    "# release box parameters\n",
    "release_depth_layer_index = 0 #5\n",
    "release_layer_num = 4\n",
    "\n",
    "# release timing\n",
    "release_time_in_days = 1\n",
    "start_year = 2011\n",
    "start_week = 1\n",
    "\n",
    "# experiment duration\n",
    "runtime_in_days = 180 #1st generation\n",
    "dt_in_minutes =  3*60# 3h timestep \n",
    "\n",
    "#output\n",
    "outputdt_in_hours =  24 \n",
    "\n",
    "\n",
    "timearrow = 1 #forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56983e65-3035-4f21-a9e5-b16b226368d5",
   "metadata": {},
   "source": [
    "## Create fieldset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "619b9e42-27f2-45ff-a98b-c2afd48792d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output_data/full_weekly_runs/urchin_weekly2011_w01_RT-180_N-10000_seed-123.nc'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(RNG_seed)\n",
    "\n",
    "def find_i_j(lon, lat, LON, LAT):\n",
    "    '''  get indices of (lon, lat) point on NEMO grid (LON,LAT)\n",
    "         lon, lat: Point to get the indice\n",
    "         LON, LAT: NEMO nav_lon, nav_lat '''\n",
    "    a = abs(LAT - lat) + abs(LON - lon)\n",
    "    j, i = np.unravel_index(a.argmin(), a.shape)\n",
    "    return (i, j)\n",
    "\n",
    "#load input data\n",
    "mask_path = Path(\"/gxfs_work1/geomar/smomw355/model_data/ocean-only/VIKING20X.L46-KFS003/nemo/suppl/\")\n",
    "mesh_mask_filename = '1_mesh_mask.nc'\n",
    "\n",
    "mesh_mask = mask_path / mesh_mask_filename\n",
    "\n",
    "mesh_hgr = xr.open_dataset(mesh_mask)\n",
    "mesh_hgr = mesh_hgr.squeeze()\n",
    "glon = mesh_hgr.glamt\n",
    "glat = mesh_hgr.gphit\n",
    "\n",
    "#window\n",
    "lattop=40\n",
    "latbottom=-20\n",
    "lonleft=-50\n",
    "lonright=15\n",
    "\n",
    "i_left, j_bottom = find_i_j(lonleft, latbottom, glon, glat)\n",
    "i_right, j_top = find_i_j(lonright, lattop, glon, glat)\n",
    "\n",
    "\n",
    "sd_i1, sd_i2 = i_left, i_right  \n",
    "sd_j1, sd_j2 = j_bottom, j_top \n",
    "\n",
    "sd_z1, sd_z2 = 0 , 14 #vertical limits indices (first 160 m , 15 levels)\n",
    "x_window=slice(i_left, i_right)\n",
    "y_window=slice(j_bottom, j_top)\n",
    "mesh_mask = mask_path / mesh_mask_filename\n",
    "\n",
    "#input data filename\n",
    "experiment_name = \"VIKING20X.L46-KFS003\"\n",
    "data_resolution = \"1d\"\n",
    "\n",
    "data_path = \"/gxfs_work1/geomar/smomw355/model_data/ocean-only/VIKING20X.L46-KFS003/nemo/output/\"\n",
    "data_path_w = \"/gxfs_work1/geomar/smomw355/model_data/ocean-only/VIKING20X.L46-KFS003/nemo/derived/1d_compressed\"\n",
    "\n",
    "years_run = np.arange(int(runtime_in_days / 365)) + start_year # all years needed for run\n",
    "\n",
    "if timearrow == -1:\n",
    "    years_run = np.sort(-np.arange(int(runtime_in_days / 365)) + start_year)# all years needed for run\n",
    "    \n",
    "    files_U_list = list(Path(data_path).glob(f'1_{experiment_name}_{data_resolution}_{start_year - len(years_run)+1}*_grid_U.nc'))\n",
    "    files_V_list = list(Path(data_path).glob(f'1_{experiment_name}_{data_resolution}_{start_year - len(years_run)+1}*_grid_V.nc'))\n",
    "    files_W_list = list(Path(data_path_w).glob(f'1_{experiment_name}_{data_resolution}_{start_year - len(years_run)+1}*_grid_W.nc'))\n",
    "\n",
    "else:\n",
    "\n",
    "    files_U_list = list(Path(data_path).glob(f'1_{experiment_name}_{data_resolution}_{start_year}*_grid_U.nc'))\n",
    "    files_V_list = list(Path(data_path).glob(f'1_{experiment_name}_{data_resolution}_{start_year}*_grid_V.nc'))\n",
    "    files_W_list = list(Path(data_path_w).glob(f'1_{experiment_name}_{data_resolution}_{start_year}*_grid_W.nc'))\n",
    "\n",
    "\n",
    "#for multiple consecutive years after stating year\n",
    "for year in years_run[1:]:\n",
    "    file_U = f'1_{experiment_name}_{data_resolution}_{year}*_grid_U.nc'\n",
    "    file_V = f'1_{experiment_name}_{data_resolution}_{year}*_grid_V.nc' \n",
    "    file_W = f'1_{experiment_name}_{data_resolution}_{year}*_grid_W.nc' \n",
    "    \n",
    "    files_U_list.append(list(Path(data_path).glob(file_U))[0])\n",
    "    files_V_list.append(list(Path(data_path).glob(file_V))[0]) \n",
    "    files_W_list.append(list(Path(data_path_w).glob(file_W))[0])\n",
    "\n",
    "#choose release depths from layers of VIKING grid \n",
    "layer_depths = mesh_hgr.nav_lev[:10].values #upper 10 layers\n",
    "depth_min = layer_depths[release_depth_layer_index]\n",
    "depth_max = layer_depths[release_depth_layer_index + release_layer_num]\n",
    "    \n",
    "    \n",
    "\n",
    "outpath = f'../output_data/full_weekly_runs/'\n",
    "output_filename = f'urchin_weekly{start_year:04d}_w{start_week:02d}_RT-{runtime_in_days}_N-{number_particles}_seed-{RNG_seed}.nc'\n",
    "\n",
    "\n",
    "if timearrow == -1:\n",
    "    output_filename = 'backtrack_' + output_filename\n",
    "    \n",
    "outpath + output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e3c930e-653b-4c70-88ff-afa7f0c4c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fieldset_defintions(\n",
    "    list_of_filenames_U, \n",
    "    list_of_filenames_V,\n",
    "    list_of_filenames_W, \n",
    "    mesh_mask\n",
    "                        ):\n",
    "    \n",
    "    filenames = {'U': {'lon': (mesh_mask),\n",
    "                       'lat': (mesh_mask),\n",
    "                       'depth': list_of_filenames_W[0],\n",
    "                       'data': list_of_filenames_U},\n",
    "                 'V': {'lon': (mesh_mask),\n",
    "                       'lat': (mesh_mask),\n",
    "                       'depth': list_of_filenames_W[0], \n",
    "                       'data': list_of_filenames_V},\n",
    "                 'W': {'lon': (mesh_mask),\n",
    "                       'lat': (mesh_mask),\n",
    "                       'depth': list_of_filenames_W[0],\n",
    "                       'data': list_of_filenames_W},\n",
    "                }\n",
    "    \n",
    "    variables = {'U': 'vozocrtx',\n",
    "                 'V': 'vomecrty',\n",
    "                 'W': 'vovecrtz',\n",
    "                }\n",
    "        \n",
    "    dimensions = {'U': {'lon': 'glamf', 'lat': 'gphif', 'depth': 'depthw',\n",
    "                        'time': 'time_counter'}, \n",
    "                  'V': {'lon': 'glamf', 'lat': 'gphif', 'depth': 'depthw',\n",
    "                        'time': 'time_counter'},  \n",
    "                  'W': {'lon': 'glamf', 'lat': 'gphif', 'depth': 'depthw',\n",
    "                        'time': 'time_counter'},  \n",
    "                 }\n",
    "    \n",
    "    indices = {\n",
    "        'U': {'depth': range(sd_z1, sd_z2), 'lon': range(sd_i1, sd_i2), 'lat': range(sd_j1, sd_j2)},\n",
    "        'V': {'depth': range(sd_z1, sd_z2), 'lon': range(sd_i1, sd_i2), 'lat': range(sd_j1, sd_j2)},\n",
    "        'W': {'depth': range(sd_z1, sd_z2), 'lon': range(sd_i1, sd_i2), 'lat':range(sd_j1, sd_j2)},\n",
    "    }    \n",
    "\n",
    "    return FieldSet.from_nemo(\n",
    "        filenames, variables, dimensions, indices=indices,\n",
    "        mesh='spherical',\n",
    "        tracer_interp_method='cgrid_tracer',\n",
    "        allow_time_extrapolation=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f745083-8e6e-46fa-9cf6-36435f8d645c",
   "metadata": {},
   "source": [
    " ## Create Fieldset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff658906-c0c6-4949-92af-c2c6bae3914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldset = fieldset_defintions(\n",
    "        files_U_list, files_V_list,\n",
    "        files_W_list,\n",
    "        mesh_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb5190-10bb-4b7c-a632-3be647cf0ae5",
   "metadata": {},
   "source": [
    "## Create particleset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a12ac7-4ad2-4d35-b4cc-bd42041284fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 10000 particles.\n"
     ]
    }
   ],
   "source": [
    "#load polygon data\n",
    "exterior = pd.read_csv(Path(\"/gxfs_work1/geomar/smomw529/2023_sea_urchin_tenerife/data/release_zone_exterior500.csv\")).values.tolist()\n",
    "interior = pd.read_csv(Path(\"/gxfs_work1/geomar/smomw529/2023_sea_urchin_tenerife/data/release_zone_interior.csv\")).values.tolist()\n",
    "\n",
    "box_poly = Polygon(exterior, [interior])\n",
    "\n",
    "#generate lat lon values for each particle inside the polygon\n",
    "in_poly = get_uniform_random_latlon_within_polygon(box_poly,N = number_particles, max_iter=20)\n",
    "\n",
    "#release time\n",
    "rel_time  = np.sort(\n",
    "   dt.datetime.fromisocalendar(start_year, start_week,1)\n",
    "    + dt.timedelta(minutes=dt_in_minutes) * np.random.randint(\n",
    "        0,\n",
    "        dt.timedelta(days=release_time_in_days) / dt.timedelta(minutes=dt_in_minutes),\n",
    "        size=(number_particles, )\n",
    "    )\n",
    ")\n",
    "\n",
    "#calc correct runtime\n",
    "corr_runtime_in_days = runtime_in_days + release_time_in_days\n",
    "\n",
    "depth = np.random.uniform(\n",
    "    depth_min,\n",
    "    depth_max,\n",
    "    size=rel_time.shape\n",
    ")\n",
    "\n",
    "#Init particle set\n",
    "pset = ParticleSet(\n",
    "    fieldset=fieldset,\n",
    "    pclass=JITParticle,\n",
    "    lat=in_poly.lat.values,\n",
    "    lon=in_poly.lon.values,\n",
    "    depth=depth,\n",
    "    time=rel_time\n",
    ") \n",
    "print(f\"Created {len(pset)} particles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43fa980-a396-4c38-a640-38917874f710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kernels and error handling\n",
    "def DeleteParticle(particle, fieldset, time): \n",
    "    particle.delete()\n",
    "    \n",
    "recovery_cases = {\n",
    "    ErrorCode.ErrorOutOfBounds: DeleteParticle\n",
    "}\n",
    "\n",
    "custom_kernel = pset.Kernel(AdvectionRK4_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a1138d-f793-4702-ab5c-60105cff2704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output_data/full_weekly_runs/urchin_weekly2011_w01_RT-180_N-10000_seed-123.nc\n"
     ]
    }
   ],
   "source": [
    "#prepare Output\n",
    "output_filenamepath = outpath + output_filename\n",
    "print(output_filenamepath)\n",
    "\n",
    "outputfile = pset.ParticleFile(\n",
    "    name=output_filenamepath,\n",
    "    outputdt=dt.timedelta(hours=outputdt_in_hours)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa99e1e-988c-4da7-81f3-0523737caa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled ArrayJITParticleAdvectionRK4_3D ==> /tmp/parcels-729666/lib42a93a8b9a90801364bd3f0572b4d4f9_0.so\n",
      "INFO: Temporary output files are stored in ../output_data/out-YUIIINVL.\n",
      "INFO: You can use \"parcels_convert_npydir_to_netcdf ../output_data/out-YUIIINVL\" to convert these to a NetCDF file during the run.\n",
      "100%|████████████████████████| 18144000.0/18144000.0 [15:57<00:00, 18957.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#execute\n",
    "pset.execute(\n",
    "    custom_kernel,\n",
    "    runtime=dt.timedelta(days=corr_runtime_in_days),\n",
    "    dt=dt.timedelta(minutes=dt_in_minutes * timearrow),\n",
    "    recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle},\n",
    "    output_file=outputfile,\n",
    ")\n",
    "\n",
    "outputfile.export()\n",
    "outputfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
